{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2303ed92",
   "metadata": {},
   "source": [
    "# MNIST Classification with JaxFlow\n",
    "This notebook demonstrates how to build and train a ResNet CNN Neural Network on the MNIST dataset using JaxFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16aa121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to use jaxflow for cpu, please install jaxflow with CPU support\n",
    "! pip install --upgrade jaxflow\n",
    "# if you want to use GPU, please install jaxflow with GPU support\n",
    "# ! pip install --upgrade jaxflow[gpu]\n",
    "# if you want to use TPU, please install jaxflow with TPU support\n",
    "# ! pip install --upgrade jaxflow[tpu]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9974ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jaxflow as jf\n",
    "from jaxflow.models import Model\n",
    "from jaxflow.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from jaxflow.initializers import GlorotUniform, Zeros\n",
    "from jaxflow.optimizers import Adam\n",
    "from jaxflow.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88023aad",
   "metadata": {},
   "source": [
    "## 1. Load and preprocess MNIST\n",
    "We first load the MNIST dataset and normalize pixel values to the [0, 1] range. We also add a channel dimension for compatibility with Conv2D layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess MNIST\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(jnp.float32) / 255.0\n",
    "x_test = x_test.astype(jnp.float32) / 255.0\n",
    "x_train = x_train[..., None]\n",
    "x_test = x_test[..., None]\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412a4eb6",
   "metadata": {},
   "source": [
    "## 2. Define the CNN model\n",
    "We define a  ResNet Block using jf.layers.Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6420a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNetBlock(jf.layers.Layer):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        # First conv + BN + ReLU\n",
    "        self.conv1 = Conv2D(filters=out_channels,\n",
    "                            kernel_size=(3,3),\n",
    "                            strides=(stride,stride),\n",
    "                            padding='SAME',\n",
    "                            use_bias=True)\n",
    "\n",
    "        # Second conv + BN (no ReLU here)\n",
    "        self.conv2 = Conv2D(filters=out_channels,\n",
    "                            kernel_size=(3,3),\n",
    "                            strides=(1,1),\n",
    "                            padding='SAME',\n",
    "                            use_bias=True)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Build conv1 on the true input...\n",
    "        self.conv1.build(input_shape)\n",
    "        self.conv2.build([input_shape[0], input_shape[1], input_shape[2], self.conv1.filters])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x, training=training)\n",
    "        out = jf.activations.relu(out)\n",
    "\n",
    "        out = self.conv2(out, training=training)\n",
    "        out += identity\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20740f37",
   "metadata": {},
   "source": [
    "###  Subclassing Model Building \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Model):\n",
    "    def __init__(self, num_classes: int = 10, name: str = \"MyCNN\"):\n",
    "        super().__init__(name=name)\n",
    "        self.conv1 = Conv2D(filters=64, kernel_size=(3,3), activation=jf.activations.relu, kernel_initializer=GlorotUniform, bias_initializer=Zeros)\n",
    "        self.pool1 = MaxPooling2D(pool_size=(2,2))\n",
    "        self.ln1 = jf.layers.LayerNormalization()\n",
    "        self.conv2 = ResNetBlock(in_channels=64, out_channels=64)\n",
    "        self.pool2 = MaxPooling2D(pool_size=(2,2))\n",
    "        self.flatten = jf.layers.GlobalAveragePooling2D()\n",
    "        self.ln2 = jf.layers.LayerNormalization()\n",
    "        self.dense1 = Dense(units=64, activation=jf.activations.relu, kernel_initializer=GlorotUniform, use_bias=False)\n",
    "        self.outputs = Dense(units=num_classes, activation=jf.activations.softmax, kernel_initializer=GlorotUniform, bias_initializer=Zeros)\n",
    "    def call(self, inputs, training: bool = False):\n",
    "        x = self.conv1(inputs, training=training)\n",
    "        x = self.pool1(x, training=training)\n",
    "        x = self.ln1(x, training=training)\n",
    "        x = self.conv2(x, training=training)\n",
    "        x = self.pool2(x, training=training)\n",
    "        x = self.flatten(x)\n",
    "        x = self.ln2(x, training=training)\n",
    "        x = self.dense1(x, training=training)\n",
    "        return self.outputs(x, training=training)\n",
    "\n",
    "# Build the model\n",
    "model = CNN(num_classes=10)\n",
    "model.build(input_shape=(None, 28, 28, 1))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198193bd",
   "metadata": {},
   "source": [
    "### OR Using the `.add()` Method (Sequential-style API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9af128",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation=jf.activations.relu, kernel_initializer=GlorotUniform, bias_initializer=Zeros,\n",
    "               padding='SAME',))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(jf.layers.LayerNormalization())\n",
    "model.add(ResNetBlock(in_channels=64, out_channels=64))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(jf.layers.GlobalAveragePooling2D())\n",
    "model.add(jf.layers.LayerNormalization())\n",
    "model.add(Dense(units=64, activation=jf.activations.relu, kernel_initializer=GlorotUniform, use_bias=False))\n",
    "model.add(Dense(units=10, activation=jf.activations.softmax, kernel_initializer=GlorotUniform, bias_initializer=Zeros))\n",
    "model.build(input_shape=(None, 28, 28, 1))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a098bc4",
   "metadata": {},
   "source": [
    "## 3. Compile and train the model\n",
    "We use the Adam optimizer and sparse categorical crossentropy loss. We train for 5 epochs with a batch size of 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8828ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001)\n",
    "loss_fn = SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss_fn=loss_fn,)\n",
    "history = model.fit(x_train, y_train, epochs=510, batch_size=128, validation_data=(x_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc77fd",
   "metadata": {},
   "source": [
    "## 4. Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a405530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24104d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred = jnp.argmax(pred, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7957004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = jf.metrics.accuracy(y_test, pred)\n",
    "precision = jf.metrics.precision(y_test, pred, average='macro',num_classes=10)\n",
    "recall = jf.metrics.recall(y_test, pred, average='macro',num_classes=10)\n",
    "f1 = jf.metrics.f1_score(y_test, pred, average='macro',num_classes=10)\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e51ffc0",
   "metadata": {},
   "source": [
    "## 5. Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a5ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(history['loss'])+1)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, history['loss'], label='Train Loss')\n",
    "plt.plot(epochs, history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3fd3a0",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "This notebook showed how to train a CNN on MNIST with JaxFlow. Feel free to experiment with different architectures, learning rates, and batch sizes to improve performance!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
