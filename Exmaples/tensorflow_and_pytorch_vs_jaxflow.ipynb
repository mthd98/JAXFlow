{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d14fa30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d14fa30",
        "outputId": "9bffff76-d721-4000-f203-9c4a72ed205a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting jaxflow[gpu]\n",
            "  Downloading jaxflow-0.1.2.dev0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting jax>=0.6.0 (from jaxflow[gpu])\n",
            "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting numpy>=2.1.0 (from jaxflow[gpu])\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m495.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: optax>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from jaxflow[gpu]) (0.2.4)\n",
            "Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.11/dist-packages (from jaxflow[gpu]) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from jaxflow[gpu]) (1.6.1)\n",
            "Collecting jaxlib<=0.6.0,>=0.6.0 (from jax>=0.6.0->jaxflow[gpu])\n",
            "  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting ml_dtypes>=0.5.0 (from jax>=0.6.0->jaxflow[gpu])\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax>=0.6.0->jaxflow[gpu]) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.6.0->jaxflow[gpu]) (1.15.3)\n",
            "Collecting jax-cuda12-plugin<=0.6.0,>=0.6.0 (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]>=0.6.0; extra == \"gpu\"->jaxflow[gpu])\n",
            "  Downloading jax_cuda12_plugin-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from optax>=0.2.4->jaxflow[gpu]) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.11/dist-packages (from optax>=0.2.4->jaxflow[gpu]) (0.1.89)\n",
            "Requirement already satisfied: etils[epy] in /usr/local/lib/python3.11/dist-packages (from optax>=0.2.4->jaxflow[gpu]) (1.12.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.1->jaxflow[gpu]) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.1->jaxflow[gpu]) (3.6.0)\n",
            "Requirement already satisfied: typing_extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.87->optax>=0.2.4->jaxflow[gpu]) (4.13.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.87->optax>=0.2.4->jaxflow[gpu]) (0.12.1)\n",
            "Collecting jax-cuda12-pjrt==0.6.0 (from jax-cuda12-plugin<=0.6.0,>=0.6.0->jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]>=0.6.0; extra == \"gpu\"->jaxflow[gpu])\n",
            "  Downloading jax_cuda12_pjrt-0.6.0-py3-none-manylinux2014_x86_64.whl.metadata (492 bytes)\n",
            "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]>=0.6.0; extra == \"gpu\"->jaxflow[gpu]) (12.5.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12>=12.1.105 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]>=0.6.0; extra == \"gpu\"->jaxflow[gpu]) (12.5.82)\n",
            "Collecting nvidia-cuda-nvcc-cu12>=12.6.85 (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]>=0.6.0; extra == \"gpu\"->jaxflow[gpu])\n",
            "  Downloading nvidia_cuda_nvcc_cu12-12.9.41-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]>=0.6.0; extra == \"gpu\"->jaxflow[gpu]) (12.5.82)\n",
            "Collecting nvidia-cudnn-cu12<10.0,>=9.8 (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]>=0.6.0; extra == \"gpu\"->jaxflow[gpu])\n",
            "  Downloading nvidia_cudnn_cu12-9.10.1.4-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cufft-cu12>=11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]>=0.6.0; extra == \"gpu\"->jaxflow[gpu]) (11.2.3.61)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12>=11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]>=0.6.0; extra == \"gpu\"->jaxflow[gpu]) (11.6.3.83)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12>=12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]>=0.6.0; extra == \"gpu\"->jaxflow[gpu]) (12.5.1.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12>=2.18.1 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]>=0.6.0; extra == \"gpu\"->jaxflow[gpu]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12>=12.1.105 in /usr/local/lib/python3.11/dist-packages (from jax-cuda12-plugin[with-cuda]<=0.6.0,>=0.6.0; extra == \"cuda12\"->jax[cuda12]>=0.6.0; extra == \"gpu\"->jaxflow[gpu]) (12.5.82)\n",
            "Downloading jax-0.6.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxflow-0.1.2.dev0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax_cuda12_plugin-0.6.0-cp311-cp311-manylinux2014_x86_64.whl (15.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax_cuda12_pjrt-0.6.0-py3-none-manylinux2014_x86_64.whl (123.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl (87.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.8/87.8 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.9.41-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (40.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.1.4-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jax-cuda12-pjrt, nvidia-cudnn-cu12, nvidia-cuda-nvcc-cu12, numpy, jax-cuda12-plugin, ml_dtypes, jaxlib, jax, jaxflow\n",
            "  Attempting uninstall: jax-cuda12-pjrt\n",
            "    Found existing installation: jax-cuda12-pjrt 0.5.1\n",
            "    Uninstalling jax-cuda12-pjrt-0.5.1:\n",
            "      Successfully uninstalled jax-cuda12-pjrt-0.5.1\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cuda-nvcc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvcc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvcc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvcc-cu12-12.5.82\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: jax-cuda12-plugin\n",
            "    Found existing installation: jax-cuda12-plugin 0.5.1\n",
            "    Uninstalling jax-cuda12-plugin-0.5.1:\n",
            "      Successfully uninstalled jax-cuda12-plugin-0.5.1\n",
            "  Attempting uninstall: ml_dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.1\n",
            "    Uninstalling jaxlib-0.5.1:\n",
            "      Successfully uninstalled jaxlib-0.5.1\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.2\n",
            "    Uninstalling jax-0.5.2:\n",
            "      Successfully uninstalled jax-0.5.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
            "tensorflow 2.18.0 requires ml-dtypes<0.5.0,>=0.4.0, but you have ml-dtypes 0.5.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.10.1.4 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.6.0 jax-cuda12-pjrt-0.6.0 jax-cuda12-plugin-0.6.0 jaxflow-0.1.2.dev0 jaxlib-0.6.0 ml_dtypes-0.5.1 numpy-2.2.6 nvidia-cuda-nvcc-cu12-12.9.41 nvidia-cudnn-cu12-9.10.1.4\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade jaxflow[gpu]\n",
        "# please restart the kernel after installing jaxflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4c417567",
      "metadata": {
        "id": "4c417567"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jaxflow as jf\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "817ddc8f",
      "metadata": {
        "id": "817ddc8f"
      },
      "source": [
        "## 1. Load and preprocess MNIST\n",
        "We first load the MNIST dataset and normalize pixel values to the [0, 1] range. We also add a channel dimension for compatibility with Conv2D layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "24e0aa1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24e0aa1b",
        "outputId": "1c7a3d4c-bde1-4d14-dda1-3ee0f0fec28a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1) (60000,) (10000, 28, 28, 1) (10000,)\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess MNIST\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.astype(jnp.float32) / 255.0\n",
        "x_test = x_test.astype(jnp.float32) / 255.0\n",
        "x_train = x_train[..., None]\n",
        "x_test = x_test[..., None]\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e88edff1",
      "metadata": {
        "id": "e88edff1"
      },
      "source": [
        "\n",
        "## 2. Define the CNN model\n",
        "We define a simple CNN with two convolutional blocks followed by a fully connected layer and an output layer.\n",
        "\n",
        "###  Subclassing Model Building\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "77b65447",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77b65447",
        "outputId": "f89d61e6-60ef-4ccb-abb8-5769626d374c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 'MyCNN' summary:\n",
            "  Block 0: <Conv2D filters=32, kernel_size=(3, 3), strides=(1, 1), padding=SAME, groups=1, built=True>\n",
            "  Block 1: <MaxPooling2D pool_size=(2, 2), strides=(2, 2), padding=VALID, dilation=(1, 1), built=True>\n",
            "  Block 2: <Conv2D filters=64, kernel_size=(3, 3), strides=(1, 1), padding=SAME, groups=1, built=True>\n",
            "  Block 3: <MaxPooling2D pool_size=(2, 2), strides=(2, 2), padding=VALID, dilation=(1, 1), built=True>\n",
            "  Block 4: <Flatten built=True, output_shape=(1, 3136)>\n",
            "  Block 5: <Dense units=128, activation=relu, built=True>\n",
            "  Block 6: <Dense units=10, activation=softmax, built=True>\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "class CNN(jf.models.Model):\n",
        "    def __init__(self, num_classes: int = 10, name: str = \"MyCNN\"):\n",
        "        super().__init__(name=name)\n",
        "        self.conv1 = jf.layers.Conv2D(filters=32, kernel_size=(3,3), activation=jf.activations.relu, kernel_initializer=jf.initializers.GlorotUniform, bias_initializer=jf.initializers.Zeros)\n",
        "        self.pool1 = jf.layers.MaxPooling2D(pool_size=(2,2))\n",
        "        self.conv2 = jf.layers.Conv2D(filters=64, kernel_size=(3,3), activation=jf.activations.relu, kernel_initializer=jf.initializers.GlorotUniform, bias_initializer=jf.initializers.Zeros)\n",
        "        self.pool2 = jf.layers.MaxPooling2D(pool_size=(2,2))\n",
        "        self.flatten = jf.layers.Flatten()\n",
        "        self.dense1 = jf.layers.Dense(units=128, activation=jf.activations.relu, kernel_initializer=jf.initializers.GlorotUniform, bias_initializer=jf.initializers.Zeros)\n",
        "        self.outputs = jf.layers.Dense(units=num_classes, activation=jf.activations.softmax, kernel_initializer=jf.initializers.GlorotUniform, bias_initializer=jf.initializers.Zeros)\n",
        "    def call(self, inputs, training: bool = False):\n",
        "        x = self.conv1(inputs, training=training)\n",
        "        x = self.pool1(x, training=training)\n",
        "        x = self.conv2(x, training=training)\n",
        "        x = self.pool2(x, training=training)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x, training=training)\n",
        "        x = self.outputs(x, training=training)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# Build the model\n",
        "model = CNN(num_classes=10)\n",
        "model.build(input_shape=(None, 28, 28, 1))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba1f2ea7",
      "metadata": {
        "id": "ba1f2ea7"
      },
      "source": [
        "## 3. Compile and train the model\n",
        "We use the Adam optimizer and sparse categorical crossentropy loss. We train for 5 epochs with a batch size of 128."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "902180b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "902180b6",
        "outputId": "ef442fb0-decf-4e7f-a9db-402ac769bd1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:06<00:00] • , loss=0.1485\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 0.1485 — val_loss: 0.0614\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:02<00:00] • , loss=0.0462\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 0.0462 — val_loss: 0.0395\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:03<00:00] • , loss=0.0295\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 0.0295 — val_loss: 0.0370\n",
            "Epoch 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:02<00:00] • , loss=0.0204\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 0.0204 — val_loss: 0.0339\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 938/938 [00:02<00:00] • , loss=0.0162\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 0.0162 — val_loss: 0.0383\n",
            "Training time:  19.923725605010986\n",
            "Model training completed.\n",
            "Model evaluation started:\n",
            "Accuracy: 0.9896999597549438, Precision: 0.989700436592102, Recall: 0.9894947409629822, F1: 0.9895975589752197\n"
          ]
        }
      ],
      "source": [
        "strat_time = time.time()\n",
        "# Train the model\n",
        "optimizer = jf.optimizers.Adam(learning_rate=0.001)\n",
        "loss_fn = jf.losses.SparseCategoricalCrossentropy()\n",
        "model.compile(optimizer=optimizer, loss_fn=loss_fn,)\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test), verbose=1)\n",
        "print(\"Training time: \", time.time() - strat_time)\n",
        "print(\"Model training completed.\")\n",
        "\n",
        "print(\"Model evaluation started:\")\n",
        "# Evaluate the model\n",
        "pred = model.predict(x_test)\n",
        "pred = jnp.argmax(pred, -1)\n",
        "accuracy = jf.metrics.accuracy(y_test, pred)\n",
        "precision = jf.metrics.precision(y_test, pred, average='macro',num_classes=10)\n",
        "recall = jf.metrics.recall(y_test, pred, average='macro',num_classes=10)\n",
        "f1 = jf.metrics.f1_score(y_test, pred, average='macro',num_classes=10)\n",
        "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e46915a",
      "metadata": {
        "id": "8e46915a"
      },
      "source": [
        "# Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3b8315d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "3b8315d6",
        "outputId": "f256c611-4d7c-44e6-95ef-9eadfcb5f33d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MyCNN\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"MyCNN\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TensorFlow\n",
        "\n",
        "# 1. Define the CNN model\n",
        "class TensorFlowCNN(tf.keras.models.Model):\n",
        "    def __init__(self, num_classes: int = 10, name: str = \"MyCNN\"):\n",
        "        super().__init__(name=name)\n",
        "        self.conv1 = tf.keras.layers.Conv2D(\n",
        "            filters=32, kernel_size=(3, 3), activation=tf.nn.relu\n",
        "        )\n",
        "        self.pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "        self.conv2 = tf.keras.layers.Conv2D(\n",
        "            filters=64, kernel_size=(3, 3), activation=tf.nn.relu\n",
        "        )\n",
        "        self.pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense1 = tf.keras.layers.Dense(units=128, activation=tf.nn.relu)\n",
        "        self.outputs = tf.keras.layers.Dense(\n",
        "            units=num_classes, activation=tf.nn.softmax\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, training: bool = False):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        return self.outputs(x)\n",
        "\n",
        "# 2. Build & inspect\n",
        "model = TensorFlowCNN(num_classes=10)\n",
        "model.build(input_shape=(None, 28, 28, 1))\n",
        "model.summary()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "aa0cf047",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa0cf047",
        "outputId": "919126d1-6f71-4d7b-d53e-d99f86fffb55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.3446 - val_loss: 0.0490\n",
            "Epoch 2/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0486 - val_loss: 0.0358\n",
            "Epoch 3/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.0308\n",
            "Epoch 4/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0263\n",
            "Epoch 5/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.0168 - val_loss: 0.0283\n",
            "Training time: 30.07s\n",
            "Model training completed.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "start_time = time.time()\n",
        "\n",
        "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
        "loss_fn   = tf.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "# add accuracy metric here\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_fn,\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(f\"Training time: {time.time() - start_time:.2f}s\")\n",
        "print(\"Model training completed.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fa459cf0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa459cf0",
        "outputId": "d42c5705-05b7-4764-e540-bae771d40778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model evaluation started:\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Accuracy:  0.9906\n",
            "Precision: 0.9997\n",
            "Recall:    0.9986\n",
            "F1 Score:  0.9991\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print(\"Model evaluation started:\")\n",
        "\n",
        "# 1. Predict class‐probabilities and pick the most likely class\n",
        "y_pred_probs = model.predict(x_test, batch_size=64, verbose=1)\n",
        "y_pred = np.argmax(y_pred_probs, axis=-1)\n",
        "\n",
        "# 2. Set up tf.keras metrics\n",
        "acc_metric   = tf.keras.metrics.Accuracy()\n",
        "prec_metric  = tf.keras.metrics.Precision()\n",
        "rec_metric   = tf.keras.metrics.Recall()\n",
        "\n",
        "# 3. Update them with true vs. predicted labels\n",
        "acc_metric.update_state(y_test, y_pred)\n",
        "prec_metric.update_state(y_test, y_pred)\n",
        "rec_metric.update_state(y_test, y_pred)\n",
        "\n",
        "# 4. Extract scalar results\n",
        "accuracy  = acc_metric.result().numpy()\n",
        "precision = prec_metric.result().numpy()\n",
        "recall    = rec_metric.result().numpy()\n",
        "# avoid division by zero just in case\n",
        "f1 = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
        "\n",
        "# 5. Print nicely\n",
        "print(\n",
        "    f\"Accuracy:  {accuracy:.4f}\\n\"\n",
        "    f\"Precision: {precision:.4f}\\n\"\n",
        "    f\"Recall:    {recall:.4f}\\n\"\n",
        "    f\"F1 Score:  {f1:.4f}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "610c8093",
      "metadata": {
        "id": "610c8093"
      },
      "source": [
        "# PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d6f4b8a",
      "metadata": {
        "id": "6d6f4b8a"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "dc2c4c66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc2c4c66",
        "outputId": "f6581358-72fb-4766-c014-b23ea5f7c5ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 14.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 500kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.59MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.33MB/s]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# 0. Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "\n",
        "# 1. Data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=2\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "# 2. Model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "model = CNN(num_classes).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "33db0f4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33db0f4f",
        "outputId": "29dd991b-80aa-4fa4-d568-fafdf95c1e1c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5]  Batch [100]  Loss: 0.5212\n",
            "Epoch [1/5]  Batch [200]  Loss: 0.1558\n",
            "Epoch [1/5]  Batch [300]  Loss: 0.1102\n",
            "Epoch [1/5]  Batch [400]  Loss: 0.0855\n",
            "Epoch [1/5]  Batch [500]  Loss: 0.0901\n",
            "Epoch [1/5]  Batch [600]  Loss: 0.0735\n",
            "Epoch [1/5]  Batch [700]  Loss: 0.0585\n",
            "Epoch [1/5]  Batch [800]  Loss: 0.0546\n",
            "Epoch [1/5]  Batch [900]  Loss: 0.0665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 completed in 14.55 seconds.\n",
            "\n",
            "Epoch [2/5]  Batch [100]  Loss: 0.0481\n",
            "Epoch [2/5]  Batch [200]  Loss: 0.0456\n",
            "Epoch [2/5]  Batch [300]  Loss: 0.0401\n",
            "Epoch [2/5]  Batch [400]  Loss: 0.0429\n",
            "Epoch [2/5]  Batch [500]  Loss: 0.0441\n",
            "Epoch [2/5]  Batch [600]  Loss: 0.0418\n",
            "Epoch [2/5]  Batch [700]  Loss: 0.0338\n",
            "Epoch [2/5]  Batch [800]  Loss: 0.0447\n",
            "Epoch [2/5]  Batch [900]  Loss: 0.0400\n",
            "Epoch 2 completed in 14.45 seconds.\n",
            "\n",
            "Epoch [3/5]  Batch [100]  Loss: 0.0247\n",
            "Epoch [3/5]  Batch [200]  Loss: 0.0252\n",
            "Epoch [3/5]  Batch [300]  Loss: 0.0260\n",
            "Epoch [3/5]  Batch [400]  Loss: 0.0253\n",
            "Epoch [3/5]  Batch [500]  Loss: 0.0314\n",
            "Epoch [3/5]  Batch [600]  Loss: 0.0230\n",
            "Epoch [3/5]  Batch [700]  Loss: 0.0283\n",
            "Epoch [3/5]  Batch [800]  Loss: 0.0265\n",
            "Epoch [3/5]  Batch [900]  Loss: 0.0268\n",
            "Epoch 3 completed in 15.44 seconds.\n",
            "\n",
            "Epoch [4/5]  Batch [100]  Loss: 0.0147\n",
            "Epoch [4/5]  Batch [200]  Loss: 0.0206\n",
            "Epoch [4/5]  Batch [300]  Loss: 0.0179\n",
            "Epoch [4/5]  Batch [400]  Loss: 0.0232\n",
            "Epoch [4/5]  Batch [500]  Loss: 0.0247\n",
            "Epoch [4/5]  Batch [600]  Loss: 0.0291\n",
            "Epoch [4/5]  Batch [700]  Loss: 0.0195\n",
            "Epoch [4/5]  Batch [800]  Loss: 0.0244\n",
            "Epoch [4/5]  Batch [900]  Loss: 0.0215\n",
            "Epoch 4 completed in 19.79 seconds.\n",
            "\n",
            "Epoch [5/5]  Batch [100]  Loss: 0.0138\n",
            "Epoch [5/5]  Batch [200]  Loss: 0.0126\n",
            "Epoch [5/5]  Batch [300]  Loss: 0.0162\n",
            "Epoch [5/5]  Batch [400]  Loss: 0.0165\n",
            "Epoch [5/5]  Batch [500]  Loss: 0.0126\n",
            "Epoch [5/5]  Batch [600]  Loss: 0.0127\n",
            "Epoch [5/5]  Batch [700]  Loss: 0.0143\n",
            "Epoch [5/5]  Batch [800]  Loss: 0.0128\n",
            "Epoch [5/5]  Batch [900]  Loss: 0.0268\n",
            "Epoch 5 completed in 14.40 seconds.\n",
            "\n",
            "Total training time over 5 epochs: 78.64 seconds.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 3. Loss & Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 4. Training loop with timing\n",
        "total_start = time.perf_counter()\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    epoch_start = time.perf_counter()\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader, 1):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if batch_idx % 100 == 0:\n",
        "            avg = running_loss / 100\n",
        "            print(f\"Epoch [{epoch}/{num_epochs}]  Batch [{batch_idx}]  Loss: {avg:.4f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "    epoch_time = time.perf_counter() - epoch_start\n",
        "    print(f\"Epoch {epoch} completed in {epoch_time:.2f} seconds.\\n\")\n",
        "\n",
        "total_time = time.perf_counter() - total_start\n",
        "print(f\"Total training time over {num_epochs} epochs: {total_time:.2f} seconds.\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0ae7941b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ae7941b",
        "outputId": "f85f8995-b27d-4af9-d244-6f373f893c86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model evaluation started:\n",
            "Accuracy:  0.9899\n",
            "Precision: 0.9899\n",
            "Recall:    0.9899\n",
            "F1 Score:  0.9898\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 5. Evaluation\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "        all_preds.append(preds)\n",
        "        all_labels.append(labels.numpy())\n",
        "\n",
        "all_preds = np.concatenate(all_preds)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "accuracy  = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "recall    = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "f1        = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "print(\"Model evaluation started:\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3LD7ZAJ1HXo4",
      "metadata": {
        "id": "3LD7ZAJ1HXo4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
